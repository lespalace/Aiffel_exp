{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d0ef46",
   "metadata": {},
   "source": [
    "# [E-11] 트랜스포머로 만드는 대화형 챗봇\n",
    "\n",
    "\n",
    "### 목차 \n",
    "\n",
    "1. 라이브러리 Import \n",
    "2. 데이터준비\n",
    "3. 데이터 전처리 & 토큰화 하기\n",
    "4. 데이터셋 만들기 \n",
    "5. 모델 구성\n",
    "6. 챗봇 테스트\n",
    "7. 모델 생성하기\n",
    "8. 모델 학습시키기 \n",
    "9. 모델 성능 평가하기\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58cf20",
   "metadata": {},
   "source": [
    "### 목표 \n",
    "\n",
    "<br> \n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다. | 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|\n",
    "|2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.| 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|\n",
    "|3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.| 한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.|\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cd97a",
   "metadata": {},
   "source": [
    "### (1) 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5479022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb4f92",
   "metadata": {},
   "source": [
    "### (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3a72c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data = pd.read_csv('~/data/ChatbotData .csv')\n",
    "chatbot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41349527",
   "metadata": {},
   "source": [
    "### (3) 데이터 전처리 & 토큰화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7561d8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "\n",
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations(questions, answers):\n",
    "    inputs, outputs = [], []\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "        inputs.append(preprocess_sentence(question))\n",
    "        outputs.append(preprocess_sentence(answer))\n",
    "        \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dda3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# data load + data 전처리\n",
    "questions, answers = load_conversations(chatbot_data['Q'], chatbot_data['A'])\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729c78d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2f61b",
   "metadata": {},
   "source": [
    "\n",
    "- TensorFlow Datasets 의 SubwordTextEncoder 를 활용해서 토큰화 하기 \n",
    "- 문장을 정수로 인코딩 / 설정 길이보다 길 경우 샘플 제거 / 최대 길이보다 짧으면 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d382540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8173]\n",
      "END_TOKEN의 번호 : [8174]\n",
      "8175\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 선언\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작, 끝 token 추가\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('START_TOKEN의 번호 :', [tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :', [tokenizer.vocab_size + 1])\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03c4c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8173]\n",
      "END_TOKEN의 번호 : [8174]\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f710be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5763, 610, 2492, 4164]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2356, 7513, 7, 6276, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf347ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8175\n",
      "필터링 후의 샘플 개수: 11823\n",
      "필터링 후의 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 40\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :', (VOCAB_SIZE))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c728cd9",
   "metadata": {},
   "source": [
    "### (4) 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203089c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10c687",
   "metadata": {},
   "source": [
    "### (5) 모델 구성\n",
    "\n",
    "#### 5-1. PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1d435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoding\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) /\n",
    "                            tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333dfea",
   "metadata": {},
   "source": [
    "#### 5-2. scaled_dot_product_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee49455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled dot product attention 함수 \n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdf71c",
   "metadata": {},
   "source": [
    "#### 5-3. MultiHeadAttention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5161030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티해드어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6631d8",
   "metadata": {},
   "source": [
    "#### 5-4. mask padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52d0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac4499",
   "metadata": {},
   "source": [
    "#### 5-5. Look-ahead Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61035052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - \\\n",
    "        tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f76cf",
   "metadata": {},
   "source": [
    "#### 5-6. Encoder 설계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8aeaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513acca",
   "metadata": {},
   "source": [
    "#### 5-7. Decoder 설계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3534462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a47f9",
   "metadata": {},
   "source": [
    "#### 5-8. Transformer 모델 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb1c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(create_padding_mask, output_shape=(1, 1, None), name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "\n",
    "# 손실함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 커스텀 된 학습률\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 정확도\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432bd25",
   "metadata": {},
   "source": [
    "### (6) 챗봇 테스트 \n",
    "\n",
    "- decoder_inference() 함수를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51adbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder 추론\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "\n",
    "\n",
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다.\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1abba",
   "metadata": {},
   "source": [
    "### (7) 모델 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ab1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3147008     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3674368     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8175)   2100975     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,922,351\n",
      "Trainable params: 8,922,351\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 생성\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fd86188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compile\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36ae2e",
   "metadata": {},
   "source": [
    "### (8) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b1fb7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 16s 53ms/step - loss: 1.4546 - accuracy: 0.0282\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.1811 - accuracy: 0.0495\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 1.0047 - accuracy: 0.0506\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.9294 - accuracy: 0.0543\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.8723 - accuracy: 0.0573\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.8139 - accuracy: 0.0612\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.7491 - accuracy: 0.0668\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.6767 - accuracy: 0.0746\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5973 - accuracy: 0.0835\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5145 - accuracy: 0.0930\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.4297 - accuracy: 0.1034\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.3486 - accuracy: 0.1146\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.2738 - accuracy: 0.1255\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.2077 - accuracy: 0.1359\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.1526 - accuracy: 0.1452\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.1097 - accuracy: 0.1533\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0800 - accuracy: 0.1587\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0601 - accuracy: 0.1623\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0507 - accuracy: 0.1638\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0449 - accuracy: 0.1646\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0414 - accuracy: 0.1650\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0406 - accuracy: 0.1651\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0361 - accuracy: 0.1661\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0320 - accuracy: 0.1673\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0278 - accuracy: 0.1682\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0246 - accuracy: 0.1690\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0217 - accuracy: 0.1697\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0201 - accuracy: 0.1701\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0185 - accuracy: 0.1705\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0166 - accuracy: 0.1709\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0156 - accuracy: 0.1713\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0140 - accuracy: 0.1717\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0128 - accuracy: 0.1720\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0127 - accuracy: 0.1719\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0113 - accuracy: 0.1723\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0108 - accuracy: 0.1724\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0104 - accuracy: 0.1725\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0092 - accuracy: 0.1729\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0091 - accuracy: 0.1730\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0085 - accuracy: 0.1731\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0084 - accuracy: 0.1731\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0076 - accuracy: 0.1733\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0071 - accuracy: 0.1734\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0072 - accuracy: 0.1734\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0064 - accuracy: 0.1736\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0064 - accuracy: 0.1736\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0060 - accuracy: 0.1736\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0056 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0057 - accuracy: 0.1737\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cf1f7",
   "metadata": {},
   "source": [
    "### (9) 모델 성능 평가하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2beb86f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 졸려\n",
      "출력 : 낮잠을 잠깐 자도 괜찮아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'낮잠을 잠깐 자도 괜찮아요 .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너무 졸려\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3db5d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 고백 해볼까?\n",
      "출력 : 용기를 내서 고백해보는 건 어떨까요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'용기를 내서 고백해보는 건 어떨까요 .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"고백 해볼까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37cf2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 커피 한잔 드실래요?\n",
      "출력 : 한 잔 하기 좋은 날이네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'한 잔 하기 좋은 날이네요 .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"커피 한잔 드실래요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a258048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 수박 먹고 싶어\n",
      "출력 : 맛있을 거 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있을 거 같아요 .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"수박 먹고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f3acba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 추워\n",
      "출력 : 따듯한 차 한잔 어때요 ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'따듯한 차 한잔 어때요 ?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"추워\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd90bdb",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a27fa",
   "metadata": {},
   "source": [
    "- Epoch 값을 25 부터 100까지 여러번 변경해 봤는데 예상대로 높을수록 성능이 더 좋았다. Epoch 값이 많이 낮은 경우 4개 중 2개를 동문서답을 했고 (<U>입력 : 커피 한잔 어떠세요?    출력 : 시원한 바람 쉬고 약먹기 ! </U>) Epoch 40은 맥락은 이해한 듯 하지만 적절한 대답이 아니라 적합하지 않다고 생각되었다. (<U> 오랜만에 설레여 -> 정말 후회할 습관이에요(음. 컴퓨터는 설레임을 모르겠죠...)   </U>). Epoch 를 100으로 할 경우 상당히 자세하고 세련된 답을 return 하는걸로 보였지만 그래도 잘못된 답을 할 때도 있어 학습시간 등을 전체적으로 고려했을 때 50이 가장 적절하다고 판단했다. \n",
    "<br>\n",
    "\n",
    "- 모델은 특히 사랑, 실연에 관련한 것은 잘 학습이 된 것 같은데, 문제는 사랑이나 실연이랑은 관련이 없는 문장을 넣어도 사랑과 관련한 답을 return 한다. (<U>입력 : 완전 짜증나   출력 : 사랑이 내맘같지 않아서 그런가봐요 </U>) 단, 감정과 무관한 입력에는 적절한 출력이 돌아오는 편이다. (<U> 입력 : 더워  출력 : 여름이네요 </U>)\n",
    "<br>\n",
    "\n",
    "- 짜증나, 챙피해와 같은 사람의 감정에 대한 입력값 일수록 핀트가 어긋나는 것은 훈련 데이터로 인한 한계라고 볼 수도 있지만 챗봇은 인간이 느낄 수 있는 복잡미묘한 수만가지 감정을 정확하게 이해하지 못한 이유일 수 있다고 생각된다. \n",
    "<br>\n",
    "\n",
    "- 어쩌면 챗봇의 성능도 아닌, 얼굴을 보고 대화하지 않고 채팅으로만 대화할 때 표정이나 목소리톤, 제스쳐 등을 보거나 들을 수 없어 상대의 감정을 제대로 파악할 수 없는 상황의 한계라고도 해석할 수 있다. 아무리 AI 가 발전해도 인간만이 할 수 있는 부분이 있는건 어쩔 수 없는 것 같다. \n",
    "<br>\n",
    "\n",
    "- Transformer 를 따라서 구현해보는것은 지난번 요약챗봇보다 개선된 성능을 확인할 수 있어 재미있지만 개념을 완벽히 이해하기는 아직 어렵다. 잘 다루기 위해서 공부를 좀 더 해야할 것 같다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
