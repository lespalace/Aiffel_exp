{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [E-09] 영화리뷰 텍스트 감성분석하기\n",
    "\n",
    "\n",
    "### 목표 : 영화 리뷰 평점 데이터를 사용하여 리뷰 감성을 분류하는 text 분류모델을 구현하기\n",
    "<br>\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1.다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다. |3가지 이상의 모델이 성공적으로 시도됨 |\n",
    "|2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.|gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 적절히 분석함|\n",
    "|3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.|네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성함|\n",
    "\n",
    "<br>\n",
    "\n",
    "### (1) 라이브러리 import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 데이터 준비\n",
    "- tokenizer는 ```Mecab```을 사용\n",
    "- 불용어도 간단하게 정의 후 전처리에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) index_to_word생성\n",
    "- ```word_to_index```를 활용해서 새로운 ```index_to_word```생성\n",
    "- 그 외에 인덱스를 입력하면 단어로 리턴해주는 함수, 단어를 입력하면 인덱스로 리턴해주는 함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 모델구성을 위한 데이터 분석 및 가공\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함 \n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 내 문장 길이 분포\n",
    "\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함 '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 적절한 최대 문장 길이 지정\n",
    "# keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49157, 41)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) validation set 구성 및 모델선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  a. validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n",
      "(20000, 41)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20000건 분리\n",
    "x_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "# validation set을 제외한 나머지는 train set\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. model 선정\n",
    "- 같은 파라미터로 3가지 모델을 학습하기로 함\n",
    "    1. 1-D CNN\n",
    "    2. LSTM\n",
    "    3. GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세가지 모델을 평가할 때, 파라미터는 고정으로 사용\n",
    "vocab_size = len(index_to_word)\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 256)         28928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          114752    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 304,209\n",
      "Trainable params: 304,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(256, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GMP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "\n",
    "GMP_model = keras.Sequential(name=\"GMP\")\n",
    "GMP_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "GMP_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "GMP_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "GMP_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GMP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3가지 모델을 같은 조건에서 학습 후 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'LSTM', 'GMP']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst = [CNN_model.name, LSTM_model.name, GMP_model.name]\n",
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start fitting CNN ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 6s 10ms/step - loss: 0.4595 - accuracy: 0.7628 - val_loss: 0.3516 - val_accuracy: 0.8463\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.3223 - accuracy: 0.8624 - val_loss: 0.3340 - val_accuracy: 0.8544\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2897 - accuracy: 0.8795 - val_loss: 0.3349 - val_accuracy: 0.8554\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2599 - accuracy: 0.8944 - val_loss: 0.3384 - val_accuracy: 0.8569\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.2249 - accuracy: 0.9116 - val_loss: 0.3646 - val_accuracy: 0.8537\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1898 - accuracy: 0.9280 - val_loss: 0.3974 - val_accuracy: 0.8501\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1554 - accuracy: 0.9433 - val_loss: 0.4308 - val_accuracy: 0.8472\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1263 - accuracy: 0.9561 - val_loss: 0.4814 - val_accuracy: 0.8439\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.1045 - accuracy: 0.9646 - val_loss: 0.5407 - val_accuracy: 0.8385\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0859 - accuracy: 0.9724 - val_loss: 0.6075 - val_accuracy: 0.8370\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0725 - accuracy: 0.9769 - val_loss: 0.6902 - val_accuracy: 0.8325\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.7159 - val_accuracy: 0.8310\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.7574 - val_accuracy: 0.8303\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0506 - accuracy: 0.9844 - val_loss: 0.7949 - val_accuracy: 0.8289\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.8365 - val_accuracy: 0.8328\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0434 - accuracy: 0.9859 - val_loss: 0.9165 - val_accuracy: 0.8303\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.9602 - val_accuracy: 0.8311\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.9888 - val_accuracy: 0.8334\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 1.0338 - val_accuracy: 0.8321\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 1.0489 - val_accuracy: 0.8293\n",
      "Start evaluating CNN ...\n",
      "1537/1537 - 3s - loss: 1.0960 - accuracy: 0.8236\n",
      "----------------------------------------\n",
      "Start fitting LSTM ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 4s 7ms/step - loss: 0.6560 - accuracy: 0.5778 - val_loss: 0.4767 - val_accuracy: 0.7983\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.4122 - accuracy: 0.8170 - val_loss: 0.3568 - val_accuracy: 0.8435\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8390 - val_loss: 0.3447 - val_accuracy: 0.8515\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3524 - accuracy: 0.8475 - val_loss: 0.3434 - val_accuracy: 0.8529\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3430 - accuracy: 0.8520 - val_loss: 0.3398 - val_accuracy: 0.8540\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8546 - val_loss: 0.3400 - val_accuracy: 0.8525\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8570 - val_loss: 0.3434 - val_accuracy: 0.8554\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3312 - accuracy: 0.8578 - val_loss: 0.3383 - val_accuracy: 0.8539\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8600 - val_loss: 0.3446 - val_accuracy: 0.8528\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3234 - accuracy: 0.8599 - val_loss: 0.3385 - val_accuracy: 0.8541\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.8618 - val_loss: 0.3457 - val_accuracy: 0.8474\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3190 - accuracy: 0.8629 - val_loss: 0.3407 - val_accuracy: 0.8491\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3172 - accuracy: 0.8637 - val_loss: 0.3397 - val_accuracy: 0.8543\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3133 - accuracy: 0.8651 - val_loss: 0.3396 - val_accuracy: 0.8540\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8662 - val_loss: 0.3409 - val_accuracy: 0.8526\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3101 - accuracy: 0.8669 - val_loss: 0.3361 - val_accuracy: 0.8554\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3090 - accuracy: 0.8668 - val_loss: 0.3433 - val_accuracy: 0.8533\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3061 - accuracy: 0.8685 - val_loss: 0.3423 - val_accuracy: 0.8543\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3057 - accuracy: 0.8671 - val_loss: 0.3375 - val_accuracy: 0.8551\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.8699 - val_loss: 0.3431 - val_accuracy: 0.8546\n",
      "Start evaluating LSTM ...\n",
      "1537/1537 - 3s - loss: 0.3485 - accuracy: 0.8518\n",
      "----------------------------------------\n",
      "Start fitting GMP ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.6056 - accuracy: 0.7332 - val_loss: 0.4398 - val_accuracy: 0.8221\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.3822 - accuracy: 0.8375 - val_loss: 0.3641 - val_accuracy: 0.8410\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8595 - val_loss: 0.3531 - val_accuracy: 0.8460\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.3041 - accuracy: 0.8724 - val_loss: 0.3521 - val_accuracy: 0.8474\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.8824 - val_loss: 0.3549 - val_accuracy: 0.8465\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.8905 - val_loss: 0.3606 - val_accuracy: 0.8458\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.8975 - val_loss: 0.3672 - val_accuracy: 0.8471\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9031 - val_loss: 0.3755 - val_accuracy: 0.8457\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2322 - accuracy: 0.9083 - val_loss: 0.3842 - val_accuracy: 0.8439\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2227 - accuracy: 0.9133 - val_loss: 0.3928 - val_accuracy: 0.8429\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2136 - accuracy: 0.9171 - val_loss: 0.4028 - val_accuracy: 0.8431\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.2057 - accuracy: 0.9209 - val_loss: 0.4124 - val_accuracy: 0.8413\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9249 - val_loss: 0.4222 - val_accuracy: 0.8393\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1911 - accuracy: 0.9282 - val_loss: 0.4330 - val_accuracy: 0.8394\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1846 - accuracy: 0.9317 - val_loss: 0.4426 - val_accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1787 - accuracy: 0.9337 - val_loss: 0.4525 - val_accuracy: 0.8368\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1730 - accuracy: 0.9368 - val_loss: 0.4640 - val_accuracy: 0.8346\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9396 - val_loss: 0.4730 - val_accuracy: 0.8340\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9418 - val_loss: 0.4854 - val_accuracy: 0.8311\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9439 - val_loss: 0.4942 - val_accuracy: 0.8312\n",
      "Start evaluating GMP ...\n",
      "1537/1537 - 2s - loss: 0.5057 - accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "model_result = {}\n",
    "\n",
    "for model_name in model_lst:\n",
    "    \n",
    "    if model_name == \"CNN\":\n",
    "        model = CNN_model\n",
    "    elif model_name == \"LSTM\":\n",
    "        model = LSTM_model\n",
    "    else :\n",
    "        model = GMP_model\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(\"Start fitting {} ...\".format(model_name))\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=20\n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "    print(\"Start evaluating {} ...\".format(model_name))\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    model_result[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM \t 0.8518420457839966\n",
      "GMP \t 0.8244807720184326\n",
      "CNN \t 0.8236263394355774\n"
     ]
    }
   ],
   "source": [
    "for name, [_, acc] in sorted(model_result.items(), key=lambda x : x[1][1], reverse=True) :\n",
    "    print(name,'\\t',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이후에 가장 성능이 좋은 모델 선택 후 파라미터 튜닝을 수행\n",
    "\n",
    "### (6) 모델 훈련\n",
    "\n",
    "- 위의 모델 중에서 LSTM의 성능이 가장 좋은것을 확인\n",
    "- 모델을 훈련하기 전에 먼저 성능을 올릴 수 있는 최적의 하이퍼파라미터를 찾아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 1000)        10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               578048    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 10,579,089\n",
      "Trainable params: 10,579,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dim = 1000  # 워드 벡터의 차원수\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "# CNN을 추가했을 때\n",
    "# model.add(keras.layers.Conv1D(8, 7, activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling1D())\n",
    "# LSTM 레이어를 두개로 학습했을 때\n",
    "# model.add(keras.layers.LSTM(256, dropout=0.7, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(128, dropout=0.7))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 이진분류\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```optimizer```에서 사용하는 ```Adam```에도 ```learning rate```를 조절해주었다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - 17s 16ms/step - loss: 0.5659 - accuracy: 0.6821 - val_loss: 0.4923 - val_accuracy: 0.7827\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78270, saving model to model.h5\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.3827 - accuracy: 0.8313 - val_loss: 0.3480 - val_accuracy: 0.8467\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78270 to 0.84665, saving model to model.h5\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.3279 - accuracy: 0.8593 - val_loss: 0.3351 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.84665 to 0.85635, saving model to model.h5\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.2995 - accuracy: 0.8720 - val_loss: 0.3292 - val_accuracy: 0.8618\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.85635 to 0.86175, saving model to model.h5\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.2740 - accuracy: 0.8846 - val_loss: 0.3290 - val_accuracy: 0.8619\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.86175 to 0.86185, saving model to model.h5\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.2535 - accuracy: 0.8937 - val_loss: 0.3373 - val_accuracy: 0.8612\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.86185\n",
      "Epoch 7/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.2359 - accuracy: 0.9013 - val_loss: 0.3353 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86185\n",
      "Epoch 8/20\n",
      "986/986 [==============================] - 15s 15ms/step - loss: 0.2184 - accuracy: 0.9096 - val_loss: 0.3548 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86185\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3578 - accuracy: 0.8566\n",
      "[0.3577619194984436, 0.85664302110672]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 학습시킨 결과 ```0.852```에서 ```0.857```로 정확도가 상승하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Loss, Accuracy 그래프 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 학습시킨 ```word2vector```를 저장시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀작성\n",
    "\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```gensim```을 사용해서 학습시킨 ```word2vector```를 사용해서 ```대박```이라는 단어와 연관성이 있는 단어들을 뽑아보았다. 데이터를 엄청난 숫자로 넣은것은 아니라 한계가 있지 않을까 했지만 그래도 긍정적인 평가들을 확인할 수 있었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('최고', 0.5967438220977783),\n",
       " ('탱고', 0.5753860473632812),\n",
       " ('즐겼', 0.567847490310669),\n",
       " ('멋져요', 0.5638055801391602),\n",
       " ('이제야', 0.5631267428398132),\n",
       " ('담백', 0.5621469020843506),\n",
       " ('웰메이드', 0.5620735883712769),\n",
       " ('진진', 0.5600122809410095),\n",
       " ('여잔데', 0.5600070953369141),\n",
       " ('따스', 0.5576196908950806)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "word_vectors.similar_by_word(\"대박\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (9) 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "<br> \n",
    "\n",
    "- 적절한 ko.bin을 찾아 이용하고 gensim 버전을 3.x.x로 낮춰야 오류가 일어나지 않음에 유의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.3 in /opt/conda/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/sentiment_classification/ko.tsv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " os.getenv('HOME')+'/aiffel/sentiment_classification/ko.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4683/2946491341.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector = word2vec['영화']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'\n",
    "word2vec = gensim.models.Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['영화']\n",
    "vector.shape     # 200dim의 워드 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('취미', 0.5857348442077637),\n",
       " ('유머', 0.5140613913536072),\n",
       " ('매력', 0.5105490684509277),\n",
       " ('흥미', 0.4988338351249695),\n",
       " ('공짜', 0.4960595667362213),\n",
       " ('일자리', 0.49294644594192505),\n",
       " ('즐거움', 0.48700767755508423),\n",
       " ('비애', 0.4836210310459137),\n",
       " ('관객', 0.48286449909210205),\n",
       " ('향수', 0.4823310971260071)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 단어와 그 유사도 확인\n",
    "word2vec.wv.most_similar(\"재미\")  # 학습이 잘 되어 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4683/3371473685.py:10: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word[i] in word2vec:\n",
      "/tmp/ipykernel_4683/3371473685.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix[i] = word2vec[index_to_word[i]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000     # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩 차례대로 카피\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,168,577\n",
      "Trainable params: 2,168,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 임베딩 + LSTM 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(keras.layers.Dropout(rate=0.4)) #dropout 추가\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4683/242381.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector = word2vec['대박']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12250227, -0.26166117,  0.1601894 ,  0.24988233, -0.19694664,\n",
       "        0.20742898,  0.23358916, -0.08032743,  0.07419734,  0.28976992,\n",
       "        0.05920417, -0.24217431,  0.42650384,  0.37083197,  0.01488842,\n",
       "       -0.15399031,  0.21594983,  0.16782928,  0.04716487, -0.3933347 ,\n",
       "        0.06105555, -0.13588727, -0.0257909 , -0.06074918,  0.04168789,\n",
       "        0.34588724,  0.24693313, -0.05122459,  0.16371667,  0.05747311,\n",
       "       -0.12627307, -0.16464052, -0.29741055,  0.17121391, -0.24180788,\n",
       "       -0.28056645, -0.06616814,  0.15681611,  0.20206362, -0.1660444 ,\n",
       "        0.00203782, -0.2563252 , -0.24074501, -0.63730514,  0.35244125,\n",
       "        0.05436644, -0.14913762, -0.06556495, -0.05610788,  0.11254067,\n",
       "       -0.09251513, -0.28059378,  0.07197419,  0.11595767,  0.15117767,\n",
       "       -0.00541334, -0.128903  ,  0.04034068, -0.22690742,  0.00775241,\n",
       "        0.16708778,  0.10937496, -0.17221814,  0.04758313,  0.321897  ,\n",
       "        0.0646909 ,  0.292136  , -0.07984147,  0.09785581,  0.181296  ,\n",
       "        0.17631158,  0.01031382, -0.43260768,  0.01173338,  0.03490037,\n",
       "       -0.0076601 , -0.06428192, -0.2924691 ,  0.24474835,  0.07950445,\n",
       "       -0.09601387, -0.34834263, -0.17978796,  0.23437631, -0.15391289,\n",
       "        0.01297345, -0.04877474, -0.22579618, -0.06827989, -0.266499  ,\n",
       "       -0.18218975, -0.45568773, -0.19330987,  0.09304521,  0.08007847,\n",
       "       -0.08579313, -0.01735996, -0.20058121, -0.11037695, -0.04257905,\n",
       "       -0.01491661,  0.24702635, -0.06080532,  0.07469252,  0.02070692,\n",
       "        0.20998064, -0.12500262, -0.16058917,  0.13576448, -0.01957137,\n",
       "       -0.03530353,  0.02538178,  0.02707971,  0.02211284,  0.4662458 ,\n",
       "       -0.13323712, -0.31756285, -0.26687905, -0.2932379 ,  0.16787444,\n",
       "       -0.00277177,  0.11576287, -0.0071318 ,  0.04130382, -0.0535576 ,\n",
       "        0.5331611 ,  0.15177174,  0.308193  ,  0.12067769, -0.11636538,\n",
       "       -0.16276449, -0.1450912 , -0.07153927,  0.00982432,  0.16283946,\n",
       "        0.16073047, -0.30461156,  0.06590325,  0.18986021,  0.22578666,\n",
       "       -0.10132927,  0.1319676 , -0.28178945,  0.03667555, -0.02295887,\n",
       "       -0.15407115, -0.3441792 , -0.1218596 , -0.3528504 , -0.14319238,\n",
       "       -0.3211591 ,  0.14814556, -0.10278759,  0.23421551,  0.08331902,\n",
       "        0.00759588,  0.39796677, -0.13322656, -0.33425966, -0.2488725 ,\n",
       "        0.22625662, -0.01530029, -0.1754215 ,  0.06301978, -0.09565204,\n",
       "        0.22803056, -0.09959741, -0.08168349,  0.02098079,  0.09322228,\n",
       "       -0.00068385, -0.18893392,  0.2519263 ,  0.05090755,  0.2681667 ,\n",
       "        0.34096426, -0.18010454,  0.16246942,  0.01820518, -0.0705201 ,\n",
       "        0.08623672, -0.01494653, -0.21275468, -0.0316746 ,  0.26614192,\n",
       "        0.02781401,  0.1385179 ,  0.38353992, -0.08111849,  0.10542663,\n",
       "       -0.19549905,  0.01497585,  0.05798322,  0.02531051, -0.04150281,\n",
       "       -0.12611519, -0.05583593, -0.07526224, -0.08963452,  0.0068798 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = word2vec['대박']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 ```word2vec```를 사용해서 ```embedding_matrix```를 생성해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4683/1073688978.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word[i] in word2vec:\n",
      "/tmp/ipykernel_4683/1073688978.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix[i] = word2vec[index_to_word[i]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,470,033\n",
      "Trainable params: 2,470,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix), \n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - 11s 10ms/step - loss: 0.4873 - accuracy: 0.7421 - val_loss: 0.3506 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.86185\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.3230 - accuracy: 0.8601 - val_loss: 0.3224 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.86185\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2777 - accuracy: 0.8832 - val_loss: 0.3091 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.86185 to 0.86730, saving model to model.h5\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2460 - accuracy: 0.8984 - val_loss: 0.3094 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.86730 to 0.86955, saving model to model.h5\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.2154 - accuracy: 0.9129 - val_loss: 0.3258 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.86955\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - 10s 10ms/step - loss: 0.1834 - accuracy: 0.9280 - val_loss: 0.3513 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.86955\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3571 - accuracy: 0.8596\n",
      "[0.35708680748939514, 0.8595724105834961]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```validation accuracy```가 증가한 것을 확인할 수 있다 \n",
    "그래프로 시각화도 해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화할 항목 세팅 \n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# 시각화 시도\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 및 회고 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음의 세가지의 모델을 사용해보았고 그 중에서 제일 높은 정확도를 성취한 LSTM 으로 선택하여 모델구조를 찾았다. \n",
    "    1. ```1D CNN``` (시계열분석, text 분석을 하는데 사용되는 신경망)\n",
    "    2. ```LSTM``` (기존의 RNN의 단점을 보완하여 장기, 단기 기억을 가능하게 설계된 신경망) \n",
    "    3. ```GlobalMaxPooling1D``` (여러개의 벡터 중 가장 큰 벡터를 반환하며 문맥을 보고 주요 특징을 뽑아낸다) \n",
    "    \n",
    "    \n",
    "- LSTM모델 앞에 CNN을 추가하면 성능이 더 나빠졌고 LSTM층을 하나 더 추가할 경우 결과는 크게 달라지지 않았지만 학습 곡선이 다르게 나타나는 것을 확인 할 수 있었다. \n",
    "- 간단하게 LSTM 레이어 하나만을 사용해서 하이퍼파라미터를 튜닝해보도록 하였다. \n",
    "- 정확도는 ```0.852``` -> ```0.857``` 으로 성능 향상\n",
    "\n",
    "- 학습한 임베딩 결과 확인\n",
    "    - '대박'이라는 단어를 통해서 유사단어를 찾아 보았다.\n",
    "    - 대부분 영화리뷰로써 긍정적인 평가를 한 결과가 나왔다.\n",
    "\n",
    "- 사전 학습된 워드임베딩적용 후 같은 파라미터로 학습 : \n",
    "    - 정확도 ```0.857``` -> ```0.860``` 로 성능 향상된 것을 확인했다.\n",
    "    \n",
    "    \n",
    "- 학습한 임베딩 결과, 대박이라는 단어를 통하서 유사단어를 찾아보았고 긍정적인 결과를 얻었다. 네이버 영화리뷰 데이터 감성분석 정확도는 85% 이상을 달성하였지만 좀 더 90% 또는 그 이상이 되려면 어떻게 해야할지가 궁금해졌고 앞으로 node 과정을 더 진행하면서 알아갈 수 있길 기대한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
